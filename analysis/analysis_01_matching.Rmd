---
title: "Matching"
author: "Yota"
date: "28 3 2022"
output: workflowr::wflow_html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
knitr::opts_knit$set(root.dir = "~/shared/datalake/mapme.protectedareas")
```


```{r include=FALSE}
# clean workspace, set options
rm(list=ls())
options(scipen=999)

# get packages
lop <- c("dplyr", "plm", "stargazer", "tidyverse", "MatchIt", "glm", "optmatch", "cobalt", "gridExtra")
newp <- lop[!(lop %in% installed.packages()[,"Package"])]
if(length(newp)) install.packages(newp)
lapply(lop, require, character.only = TRUE)

```


```{r Propensity Score Matching (PSM), echo=TRUE}
#------- Select years and prepare table -------

# Years with matching frames. Years without treatment starting years (no BMZ number started in these years) 2003, 2017, 2018, 2020
T_year <- c(2004:2016, 2019)

T_year <- c(2015)
for (i in T_year) {
  
  #------- Load matching frames -------
  #file <- paste0("matching_frame_",i)
  df <- 
    read_csv(paste("./output/matching/matching_frames/matching_frame_",i,".csv", sep = "")) %>% 
    select(id, poly_id, treatment, everything())
  
   df <- df %>% 
    filter(! is.na(country),
           ! is.na(clay_content_10_cm))
   
  #------- NN PS matching w/ replacement and exact matching 'country'-------
  
#  tryCatch({
    
    # Get propensity scores
    glm_out1 <- glm(treatment ~ 
                     travel_time_to_nearby_cities_min_5k_100mio + 
                     clay_content_10_cm + 
                     terrain_ruggedness_index_mean +
                     elevation_mean + 
                     as.factor(country) +
                     fc_area_matchingyear +
                     sum_fcl_matchingyear_tmax,
                   family = binomial(link = "probit"), 
                   data = df)
      
    
    stargazer(glm_out1,
              summary=TRUE,
              type="text",
              title = paste0("Probit regression for matching frame ",i),
              out = paste0("../../datalake/mapme.protectedareas/output/plots/propensity_score_matching/probit_summary_",i,".html"))
    
  
    m_out1 <- matchit(treatment ~
                        travel_time_to_nearby_cities_min_5k_100mio +
                        clay_content_10_cm +
                        terrain_ruggedness_index_mean +
                        elevation_mean +
                        as.factor(country) +
                        fc_area_matchingyear +
                        sum_fcl_matchingyear_tmax,
                      data = df,
                      method = "nearest",
                      replace = TRUE,
                      exact = ~ as.factor(country),
                      distance = "glm", 
                      discard = "both", # common support: drop units from both groups 
                      link = "probit")
    
    print(m_out1)
    print(summary(m_out1, un = FALSE))
    
    # Balance table
    bal_table <- bal.tab(m_out1, un = TRUE)
    print(bal_table)
    
    
    # Matched data
    m_data1 <- match.data(m_out1)
    
    ## Export data
    write_csv(m_data1, 
          paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/PSM/ps_matched_data_", i, ".csv"))
  
#  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
  
}
```

```{r Coarsened Exact Matching (CEM), echo=TRUE}
# Years with matching frames. Years without treatment starting years (no BMZ number started in these years) 2003, 2017, 2018, 2020
T_year <- c(2004:2016, 2019)
T_year <- c(2015)
# Load cutpoints (use cutpoints from dummy CEM matching for 2015)
cutoffs_list <- c()
cutoffs_list$travel_time_to_nearby_cities_min_5k_100mio <-
  c(0,120,300, 400, 500, 600, 800, 1000, 1500, 2000, 3000, max(static.df$travel_time_to_nearby_cities_min_5k_100mio,na.rm = T)) # 0-2hrs, 2-6 hrs, >6 hrs
cutoffs_list$terrain_ruggedness_index_mean <- c(0,5,10,max(static.df$terrain_ruggedness_index_mean,na.rm = T))
cutoffs_list$elevation_mean <- c(0,500,1500,max(static.df$elevation_mean,na.rm = T))
cutoffs_list$sum_fcl_matchingyear_tmax <- c(-1,0, 1, 10, 100, 200, 300, 400, 500, 600, 1000, max(static.df$sum_fcl_matchingyear_tmax))


cutoffs_list$clay_content_10_cm <- c(2.440179, 6.091119,  9.742059, 13.392999, 17.043938, 20.694878, 24.345818, 27.996758, 31.647698, 35.298637, 38.949577, 42.600517, 46.251457, 49.902397, 53.553337, 57.204276, 60.855216, 64.506156)
cutoffs_list$fc_area_matchingyear <- c(0.0000,  509.4486, 1018.8973, 1528.3459, 2037.7946, 2547.2432, 3056.6918, 3566.1405, 4075.5891, 4585.0378, 5094.4864, 5603.9350, 6113.3837, 6622.8323, 7132.2810, 7641.7296, 8151.1782, 8660.6269)


for (i in T_year) {
  
  #------- Load matching frames -------
  
  df <- 
    read_csv(paste("./output/matching/matching_frames/matching_frame_",i,".csv", sep = "")) %>% 
    select(id, poly_id, treatment, everything())
  
  
  # Prepare df for matching (no NA allowed)
  df_match <- df %>% 
    filter(! is.na(country),
           ! is.na(clay_content_10_cm))
  
  #------- Perform CEM -------
  
#  tryCatch({
    
    m_out2 <- matchit(treatment ~
                        travel_time_to_nearby_cities_min_5k_100mio +
                        clay_content_10_cm +
                        terrain_ruggedness_index_mean +
                        elevation_mean +
                        as.factor(country) +
                        fc_area_matchingyear +
                        sum_fcl_matchingyear_tmax,
                      data = df_match,
                      method = "cem",
                      cutpoints = cutoffs_list)
    
    # Matching summary
    print(m_out2)
    print(summary(m_out2, un = FALSE))
    
    # Balance table
    bal_table <- bal.tab(m_out2, un = TRUE)
    print(bal_table)
    
    # Matched data
    m_data2 <- match.data(m_out2) 
    
    ## Export data
    write_csv(m_data2, 
              paste0("../../datalake/mapme.protectedareas/output/tabular/regression_input/CEM/ce_matched_data_", i, ".csv"))
    
#  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
  
}

```

