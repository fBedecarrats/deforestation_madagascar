---
title: "Net Forest Carbon Flux"
author: "Om Prakash Bhandari (Author), Johannes Schielein (Review)"
date: "3/5/2021"
output: workflowr::wflow_html
---

```{r setup, message=FALSE}

# load required libraries
library("terra")
library("sf")
library("wdpar")
library("dplyr")
library("rmarkdown") # only used for rendering tables for this website

starttime<-Sys.time() # mark the start time of this routine to calculate processing time at the end
```

We will now use a function from our repository. If you have downloaded our repository to your local machine, you can call the function as given below with the `source`command.  If you do not have a local copy, you can download the source-code for the function [here](https://github.com/openkfw/mapme.protectedareas/tree/main/code).
```{r loadlsource, warning=FALSE, include=TRUE}

source("code/carbon-flux.R")
```

# Introduction

Forest Carbon Emissions are greenhouse gas emissions that originate from forest cover loss and subsequent Above Ground Biomass and Below Ground Biomass loss. Forest cover loss might be the result of either anthropogenic deforestation or disasters such as forest fires and same goes for biomass loss too. Forest acts as both a Source and Sink for Carbon. Sink, when the forest absorbs more carbon than it releases. Source, when forest releases more carbon than it absorbs. To determine whether forests in defined zone acts as source or sink of carbon, net forest carbon flux is calculated which represents the net exchange of carbon between forests and the atmosphere.

### Datasource and Metadata Information

- Dataset: Net Forest Carbon Flux - Global Forest Watch (Harris et al. (2021))
- Geographical Coverage: Global
- Spatial resolution: 30 meter
- Temporal Coverage: 2001-2019
- Temporal resolution: Annual Updates
- Unit: megagrams CO2 emissions/ha
- Data downloaded: 5th March, 2021
- [Metadata Link](https://data.globalforestwatch.org/datasets/gfw::forest-greenhouse-gas-net-flux/about)
- [Download Link](https://data.globalforestwatch.org/datasets/66eafb4f16f9478c828c3225d26b4989/explore?location=8.142295%2C0.000000%2C2.60)

### Processing Workflow

The purpose of this analysis is to compute net forest carbon flux for the desired wdpa polygons. This is achieved through zonal statistics operation. A zonal statistics operation is one that calculates statistics on cell values of a raster (a value raster) within the zones defined by another dataset [ArcGIS definition].

To calculate zonal statistics for net forest carbon flux that changed between 2001 to 2019, following processing routine is followed in this analysis:
  

![](assets/workflows/carbon_flux_zonal_stats.png)


# Download and prepare WDPA polygons

Since we already prepared raster data for our analysis. Now, we will try to get the country level polygon data from `wdpar` package. `wdpar` is a library to interface to the World Database on Protected Areas (WDPA). The library is used to monitor the performance of existing PAs and determine priority areas for the establishment of new PAs. We will use Brazil - for other countries of your choice, simply provide the country name or the ISO name e.g. Gy for Guyana, COL for Colombia

```{r fetchWdpar, warning=FALSE, include=TRUE}

# fetch the raw data from wdpar of country
br_wdpa_raw <- wdpa_fetch("Brazil")
```

Since there are more than 3000 enlisted protected areas in Brazil, we want to compute zonal statistics only for the polygon data of:
  - Reserva Biologica Do Rio Trombetas - wdpaid 43,
	- Reserva Extrativista Rio Cajari - wdpaid 31776, and
	- Estacao Ecologica Do Jari - wdpaid 4891

For this, we have to subset the country level polygon data to the pa level.

```{r subset, warning=FALSE, include=TRUE}

# subset three wdpa polygons by their wdpa ids
br_wdpa_subset <-
  br_wdpa_raw%>%
  filter(WDPAID %in% c(43,4891,31776))
```


The next immediate step would be to clean the fetched raw data with the functionality provided with routines from the `wdpar` package. Cleaning is done by the package following this steps:

- exclude protected areas that are not yet implemented
- exclude protected areas with limited conservation value
- replace missing data codes (e.g. "0") with missing data values (i.e. NA)
- replace protected areas represented as points with circular protected areas that correspond to their reported extent
- repair any topological issues with the geometries

```{r cleanWdpar, warning=FALSE, include=TRUE}

# clean the data
br_wdpa_subset <- wdpa_clean(
  br_wdpa_subset, 
  erase_overlaps = F
  )
# SpatialPolygonsDataFrame for sf compatibility
br_wdpa_subset_sf <- 
  st_as_sf(br_wdpa_subset)
# transform to WGS84
br_wdpa_subset_sf <- st_transform(br_wdpa_subset_sf,
                                  "+proj=longlat +datum=WGS84 +no_defs")
# we can plot the polygon data to see the three selected polygons
plot(br_wdpa_subset_sf[1])
```


# Download and prepare raster data

### Using API

The script `carbon-flux.R` contains the function to download the raster file of the desired grid.

How to use the function?

- call the function `get_net_carbon_flux` by passing (lat, lon) arguments as string for eg. ("10S_050W") or ("10N_020E")
- check the coordinates of your desired area and find out the grid under which interval of latitude and longitude does it fall
- or simply visit the [GFW Dataset Portal](https://data.globalforestwatch.org/datasets/66eafb4f16f9478c828c3225d26b4989/explore?location=8.142295%2C0.000000%2C2.60) to verify chosen grid coordinates
- Note: If in case you choose to compute zonal statistics for larger polygon level or for many polygon levels, then one raster data might not be enough for your computation. Then you must download multiple raster files so as to cover the polygon extent and merge them later simply using `merge` function.


```{r callFunction, warning=FALSE, include=TRUE}

options(timeout=180) # sets timeout for downloads to 180seconds
# call the function to download raster for a part of the country Brazil where we want to compute zonal statistics
# Note: raster value is 'Mg_CO2_ha-1'
myRaster <- 
  get_net_carbon_flux("00N_060W")
```

After successfully running this function, you can see that the raster file is downloaded and stored in the temporary directory of R and is loaded to the working directory as the layer name `myRaster` as class object 'SpatRaster'.

```{r loadRaster, warning=FALSE, include=TRUE}

# view raster metadata
myRaster
# plot the raster
plot(myRaster)
```

### Using Archived File

The entire processing routine can be implemented using archived raster file which are stored in datalake. The only difference will be, we load the raster from datalake rather than downloading the raster by calling the function `get_net_carbon_flux`. Doing so will eliminate the possible connection issues to the data server and will speed up the processing routine. 

Simply, to save further processing time and to avoid complexities, we would use the index shapefiles to load the particular raster which intersects with the PA polygon.
For this, we load the index shapefiles generated for the carbon flux rasters.
```{r indexShp, warning=FALSE, include=TRUE}

# load index shapefile
index <- 
  read_sf("../../datalake/mapme.protectedareas/processing/net_carbon_flux/raster_index/raster_index.shp")
# transform to wgs84
index <- st_transform(index,
                      "+proj=longlat +datum=WGS84 +no_defs")
```

Lets have a look at how does the index polygon looks like:
```{r plotIndex, warning=FALSE}

plot(index)
```

From the plot, we can see that the index polygon covers the entire Latin America on 10*10 grids. In order to load the required rasters, we need to intersect the index polygon and the WDPA polygon.

```{r cropIndex, warning=FALSE, include=TRUE}

# crop the index with wdpa polygon
br_crop <- st_crop(index,
                   br_wdpa_subset_sf)
# check the number of rasters having intersection with the polygon
n <- nrow(br_crop)
n
```

Hence, the polygon we selected intersects only with the one carbon flux raster.

Now the raster file is loaded to the working directory as the layer name `myRaster_ar` as class object 'SpatRaster'.

```{r viewArchivedRast, warning=FALSE, include=TRUE}

# view raster metadata
myRaster_ar <- 
  rast(br_crop$location)
# plot the raster
plot(myRaster_ar)
```

Note: For this routine, we are using `myRaster_ar`, the archived one.


# Crop the Carbon Flux Raster

As we completed raster and vector data preparation, the next step would be to clip the raster layer by the selected shapefile polygon both by its extent and mask layer. If we clip by extent, it does clipping the raster by its bounding box. However, mask layer clipping returns the raster to defined vector polygon layer.

```{r cropRaster, warning=FALSE, include=TRUE}

# extent preparation; SpatVector for `terra` compatibility
myExtent <- 
  vect(br_wdpa_subset_sf)
# crop raster using polygon extent
myCrop <- terra::crop(myRaster_ar,
                      myExtent)
# plot the data - shows the raster after getting cropped by the extent of polygon
plot(myCrop)
# crop raster using polygon mask
myMask <- terra::mask(myCrop,
                      myExtent)
# plot the data - shows the raster after getting cropped by the polygon mask
plot(myMask)
```



# Rasterize the polygon layer

To compute the zonal statistics, it is necessary to rasterize the polygon layer. Doing so, values are transferred from the spatial objects to raster cells. We need to pass the extent layer and the mask layer to the rasterize function.

```{r rasterize, warning=FALSE, include=TRUE}

# rasterize
r <- terra::rasterize(myExtent, myMask, myExtent$WDPAID, background=NA, update=FALSE, touches=is.lines(myExtent), cover=FALSE)
```


# Compute zonal statistics

A zonal statistics operation is one that calculates statistics on cell values of a raster (a value raster) within the zones defined by another dataset [ArcGIS definition].


```{r zoneStats, warning=FALSE, include=TRUE}

# zonal stats
zstats <- zonal(myMask, r, fun='sum', na.rm=T)
# create dataframe
df.zstats <- data.frame(WDPAID=NA,
                        Net_Forest_Carbon_Flux=NA)
# rename column to match with dataframe
colnames(zstats) <- colnames(df.zstats)
# view the data
rbind(df.zstats,zstats)[-1,]
```
By mathematical definition, net forest carbon flux is the difference between average annual gross emissions and average annual gross removals. Hence, positive result denotes forests as net sources of carbon and negative results denotes forests as net sinks of carbon.

For all the three polygons we considered, we got the negative result. That means forests in these three Protected Areas act as the net sinks of carbon.

**Note: If the polygon of interest intersects with multiple rasters, we have two methods to get the zonal statistics: **<br/> <br/>
*1. load all rasters - merge them into one single raster using `terra:merge` - follow the processing routine - compute zonal statistics* <br/> <br/>
*2. load individual raster - follow the processing routine - get zonal stats for individual rasters - aggregate the results* <br/> <br/>

In the end we are going to have a look how long the rendering of this file took so that we can get an idea about the processing speed of this routine.
```{r time, warning=FALSE, include=TRUE}

stoptime<-Sys.time()
print(starttime-stoptime)
```

### References

[1] Harris, N.L., D.A. Gibbs, A. Baccini, R.A. Birdsey, S. de Bruin, M. Farina, L. Fatoyinbo, M.C. Hansen, M. Herold, R.A. Houghton, P.V. Potapov, D. Requena Suarez, R.M. Roman-Cuesta, S.S. Saatchi, C.M. Slay, S.A. Turubanova, A. Tyukavina. 2021. Global maps of twenty-first century forest carbon fluxes. Nature Climate Change. https://doi.org/10.1038/s41558-020-00976-6
